{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nannotations_path = []\nfor dirname, _, filenames in os.walk('/kaggle/input/face-mask-detection/annotations'):\n    for filename in filenames:\n        annotations_path.append(os.path.join(dirname, filename))\nimages_path = []\nfor dirname, _, filenames in os.walk('/kaggle/input/face-mask-detection/images'):\n    for filename in filenames:\n        images_path.append(os.path.join(dirname, filename))\n        \nannotations_path.sort()\nimages_path.sort()\n\nimport torch\nprint(torch.cuda.memory_summary(device=None, abbreviated=False))\n#torch.cuda.empty_cache()\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_equation_line_y(tangent, constant, x):\n        return tangent*x +constant\n    \ndef get_equation_line_x(tangent, constant, y):\n    return round((y+constant)/tangent)\n\ndef create_mask(xmin, xmax, ymin, ymax, i, masks):\n    two_third_y = (ymax - ymin)*2/3 + ymin\n    third_x = (xmax - xmin)/3 + xmin\n    two_third_x = (xmax-xmin)*2/3 + xmin\n    tangent_left = (two_third_y - ymax)/(xmin - third_x)\n    constant_left = two_third_y - tangent_left*xmin\n    tangent_right = -tangent_left\n    constant_right = two_third_y - tangent_right*xmax\n    \n    '''for y in range(ymin, ymax):\n        if y<two_third_y:\n            masks[xmin:xmax,y, i] = 1\n        else:\n            for x in range(xmin, xmax-1):\n                if y<get_equation_line_y(tangent_left, constant_left, x) and y<get_equation_line_y(tangent_right, constant_right, x):\n                        masks[x,y,i] = 1\n    '''\n    for y in range(ymin, ymax):\n        if y<two_third_y:\n            masks[xmin-1,y, i] = 1\n            masks[xmax-2,y, i] = 1\n        else:\n            for x in range(get_equation_line_x(tangent_left, -constant_left, y)-1,\n                           get_equation_line_x(tangent_right, -constant_right, y)-2):\n                masks[x,y,i] = 1\n    return masks","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import torchvision\nfrom torchvision import transforms, datasets, models\nimport torch\nfrom PIL import Image\nimport xml.etree.ElementTree as et\n\nclass MaskDataset(object):\n    def __init__(self, transforms):\n        self.transforms = transforms\n        self.imgs = list(sorted(os.listdir(\"/kaggle/input/face-mask-detection/images/\")))\n    \n    def __getitem__ (self, idx):\n        img_path = os.path.join('/kaggle/input/face-mask-detection/images/maksssksksss' + str(idx) + '.png')\n        annotation_path = os.path.join(\"/kaggle/input/face-mask-detection/annotations/maksssksksss\" + str(idx) + \".xml\")\n        img = Image.open(img_path).convert(\"RGB\")\n        target = {}\n        with open(annotation_path) as annotation:\n            xml = et.parse(annotation)\n            root = xml.getroot()\n            bounding_boxes = []\n            labels = []\n            for i in range(4,len(root)):\n                #bounding_boxes.append([root[i][5][0].text,\n                #                           root[i][5][1].text, root[i][5][2].text, root[i][5][3]])\n                bounding_boxes.append([int(root[i][5][0].text),\n                                           int(root[i][5][1].text), int(root[i][5][2].text), int(root[i][5][3].text)])\n                if root[i][0].text== 'with_mask':\n                    labels.append(1)\n                elif root[i][0].text=='without_mask':\n                    labels.append(2)\n                else:\n                    labels.append(3)\n                    \n            masks = np.zeros([int(root[2][0].text), int(root[2][1].text), len(bounding_boxes)], dtype='uint8')\n            for i in range(len(bounding_boxes)):\n                box = bounding_boxes[i]\n                col_s, col_e = box[1], box[3]\n                row_s, row_e = box[0], box[2]\n                masks = create_mask(row_s, row_e, col_s, col_e, i, masks)\n            \n            \n            boxes = torch.as_tensor(bounding_boxes, dtype=torch.float32)\n            \n            labels = torch.as_tensor(labels, dtype=torch.int64)\n            \n            img_id = torch.tensor([idx])\n            \n            masks = torch.as_tensor(masks, dtype=torch.int8)\n            \n            target[\"boxes\"] = boxes\n            target[\"labels\"] = labels\n            target[\"masks\"] = masks\n            target[\"image_id\"] = img_id\n            \n        if self.transforms is not None:\n            img = self.transforms(img)\n        \n        return img, target\n    \n    def __len__(self):\n        return len(self.imgs)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\n\ndata_transform = transforms.Compose([\n        transforms.ToTensor(), \n])\n\ndef collate_fn(batch):\n    return tuple(zip(*batch))\n\ntrain_dataset = []\nvalid_dataset = []\ndataset = MaskDataset(data_transform)\nfor i in range(len(dataset)):\n    if i % 5 == 0:\n        valid_dataset.append(dataset[i])\n    else:\n        train_dataset.append(dataset[i])\n\ntrain_data_loader = torch.utils.data.DataLoader(\n  train_dataset, batch_size=4, collate_fn=collate_fn)\n\nvalid_data_loader = torch.utils.data.DataLoader(\n  valid_dataset, batch_size=4, collate_fn=collate_fn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nfor imgs, annotations in train_data_loader:\n    imgs = list(img.to(device) for img in imgs)\n    annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]\n    for i in range(len(imgs)):\n        print(len(annotations[i][\"masks\"]))\n        print(len(annotations[i][\"masks\"][0]))\n        print(len(annotations[i][\"masks\"][0][0]))\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n\n# load an instance segmentation model pre-trained pre-trained on COCO\nmodel = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n# get number of input features for the classifier\nin_features = model.roi_heads.box_predictor.cls_score.in_features\n# replace the pre-trained head with a new one\nmodel.roi_heads.box_predictor = FastRCNNPredictor(in_features, 4)\n\n# now get the number of input features for the mask classifier\nin_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\nhidden_layer = 256\n# and replace the mask predictor with a new one\nmodel.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,\n                                                       hidden_layer,\n                                                       4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#forrÃ¡s : https://github.com/matterport/Mask_RCNN\n\nfrom collections import defaultdict, deque\nimport datetime\nimport pickle\nimport time\n\nimport torch\nimport torch.distributed as dist\n\nimport errno\nimport os\n\n\nclass SmoothedValue(object):\n    \"\"\"Track a series of values and provide access to smoothed values over a\n    window or the global series average.\n    \"\"\"\n\n    def __init__(self, window_size=20, fmt=None):\n        if fmt is None:\n            fmt = \"{median:.4f} ({global_avg:.4f})\"\n        self.deque = deque(maxlen=window_size)\n        self.total = 0.0\n        self.count = 0\n        self.fmt = fmt\n\n    def update(self, value, n=1):\n        self.deque.append(value)\n        self.count += n\n        self.total += value * n\n\n    def synchronize_between_processes(self):\n        \"\"\"\n        Warning: does not synchronize the deque!\n        \"\"\"\n        if not is_dist_avail_and_initialized():\n            return\n        t = torch.tensor([self.count, self.total], dtype=torch.float64, device='cuda')\n        dist.barrier()\n        dist.all_reduce(t)\n        t = t.tolist()\n        self.count = int(t[0])\n        self.total = t[1]\n\n    @property\n    def median(self):\n        d = torch.tensor(list(self.deque))\n        return d.median().item()\n\n    @property\n    def avg(self):\n        d = torch.tensor(list(self.deque), dtype=torch.float32)\n        return d.mean().item()\n\n    @property\n    def global_avg(self):\n        return self.total / self.count\n\n    @property\n    def max(self):\n        return max(self.deque)\n\n    @property\n    def value(self):\n        return self.deque[-1]\n\n    def __str__(self):\n        return self.fmt.format(\n            median=self.median,\n            avg=self.avg,\n            global_avg=self.global_avg,\n            max=self.max,\n            value=self.value)\n\n\ndef all_gather(data):\n    \"\"\"\n    Run all_gather on arbitrary picklable data (not necessarily tensors)\n    Args:\n        data: any picklable object\n    Returns:\n        list[data]: list of data gathered from each rank\n    \"\"\"\n    world_size = get_world_size()\n    if world_size == 1:\n        return [data]\n\n    # serialized to a Tensor\n    buffer = pickle.dumps(data)\n    storage = torch.ByteStorage.from_buffer(buffer)\n    tensor = torch.ByteTensor(storage).to(\"cuda\")\n\n    # obtain Tensor size of each rank\n    local_size = torch.tensor([tensor.numel()], device=\"cuda\")\n    size_list = [torch.tensor([0], device=\"cuda\") for _ in range(world_size)]\n    dist.all_gather(size_list, local_size)\n    size_list = [int(size.item()) for size in size_list]\n    max_size = max(size_list)\n\n    # receiving Tensor from all ranks\n    # we pad the tensor because torch all_gather does not support\n    # gathering tensors of different shapes\n    tensor_list = []\n    for _ in size_list:\n        tensor_list.append(torch.empty((max_size,), dtype=torch.uint8, device=\"cuda\"))\n    if local_size != max_size:\n        padding = torch.empty(size=(max_size - local_size,), dtype=torch.uint8, device=\"cuda\")\n        tensor = torch.cat((tensor, padding), dim=0)\n    dist.all_gather(tensor_list, tensor)\n\n    data_list = []\n    for size, tensor in zip(size_list, tensor_list):\n        buffer = tensor.cpu().numpy().tobytes()[:size]\n        data_list.append(pickle.loads(buffer))\n\n    return data_list\n\n\ndef reduce_dict(input_dict, average=True):\n    \"\"\"\n    Args:\n        input_dict (dict): all the values will be reduced\n        average (bool): whether to do average or sum\n    Reduce the values in the dictionary from all processes so that all processes\n    have the averaged results. Returns a dict with the same fields as\n    input_dict, after reduction.\n    \"\"\"\n    world_size = get_world_size()\n    if world_size < 2:\n        return input_dict\n    with torch.no_grad():\n        names = []\n        values = []\n        # sort the keys so that they are consistent across processes\n        for k in sorted(input_dict.keys()):\n            names.append(k)\n            values.append(input_dict[k])\n        values = torch.stack(values, dim=0)\n        dist.all_reduce(values)\n        if average:\n            values /= world_size\n        reduced_dict = {k: v for k, v in zip(names, values)}\n    return reduced_dict\n\n\nclass MetricLogger(object):\n    def __init__(self, delimiter=\"\\t\"):\n        self.meters = defaultdict(SmoothedValue)\n        self.delimiter = delimiter\n\n    def update(self, **kwargs):\n        for k, v in kwargs.items():\n            if isinstance(v, torch.Tensor):\n                v = v.item()\n            assert isinstance(v, (float, int))\n            self.meters[k].update(v)\n\n    def __getattr__(self, attr):\n        if attr in self.meters:\n            return self.meters[attr]\n        if attr in self.__dict__:\n            return self.__dict__[attr]\n        raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n            type(self).__name__, attr))\n\n    def __str__(self):\n        loss_str = []\n        for name, meter in self.meters.items():\n            loss_str.append(\n                \"{}: {}\".format(name, str(meter))\n            )\n        return self.delimiter.join(loss_str)\n\n    def synchronize_between_processes(self):\n        for meter in self.meters.values():\n            meter.synchronize_between_processes()\n\n    def add_meter(self, name, meter):\n        self.meters[name] = meter\n\n    def log_every(self, iterable, print_freq, header=None):\n        i = 0\n        if not header:\n            header = ''\n        start_time = time.time()\n        end = time.time()\n        iter_time = SmoothedValue(fmt='{avg:.4f}')\n        data_time = SmoothedValue(fmt='{avg:.4f}')\n        space_fmt = ':' + str(len(str(len(iterable)))) + 'd'\n        if torch.cuda.is_available():\n            log_msg = self.delimiter.join([\n                header,\n                '[{0' + space_fmt + '}/{1}]',\n                'eta: {eta}',\n                '{meters}',\n                'time: {time}',\n                'data: {data}',\n                'max mem: {memory:.0f}'\n            ])\n        else:\n            log_msg = self.delimiter.join([\n                header,\n                '[{0' + space_fmt + '}/{1}]',\n                'eta: {eta}',\n                '{meters}',\n                'time: {time}',\n                'data: {data}'\n            ])\n        MB = 1024.0 * 1024.0\n        for obj in iterable:\n            data_time.update(time.time() - end)\n            yield obj\n            iter_time.update(time.time() - end)\n            if i % print_freq == 0 or i == len(iterable) - 1:\n                eta_seconds = iter_time.global_avg * (len(iterable) - i)\n                eta_string = str(datetime.timedelta(seconds=int(eta_seconds)))\n                if torch.cuda.is_available():\n                    print(log_msg.format(\n                        i, len(iterable), eta=eta_string,\n                        meters=str(self),\n                        time=str(iter_time), data=str(data_time),\n                        memory=torch.cuda.max_memory_allocated() / MB))\n                else:\n                    print(log_msg.format(\n                        i, len(iterable), eta=eta_string,\n                        meters=str(self),\n                        time=str(iter_time), data=str(data_time)))\n            i += 1\n            end = time.time()\n        total_time = time.time() - start_time\n        total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n        print('{} Total time: {} ({:.4f} s / it)'.format(\n            header, total_time_str, total_time / len(iterable)))\n\n\ndef collate_fn(batch):\n    return tuple(zip(*batch))\n\n\ndef warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor):\n\n    def f(x):\n        if x >= warmup_iters:\n            return 1\n        alpha = float(x) / warmup_iters\n        return warmup_factor * (1 - alpha) + alpha\n\n    return torch.optim.lr_scheduler.LambdaLR(optimizer, f)\n\n\ndef mkdir(path):\n    try:\n        os.makedirs(path)\n    except OSError as e:\n        if e.errno != errno.EEXIST:\n            raise\n\n\ndef setup_for_distributed(is_master):\n    \"\"\"\n    This function disables printing when not in master process\n    \"\"\"\n    import builtins as __builtin__\n    builtin_print = __builtin__.print\n\n    def print(*args, **kwargs):\n        force = kwargs.pop('force', False)\n        if is_master or force:\n            builtin_print(*args, **kwargs)\n\n    __builtin__.print = print\n\n\ndef is_dist_avail_and_initialized():\n    if not dist.is_available():\n        return False\n    if not dist.is_initialized():\n        return False\n    return True\n\n\ndef get_world_size():\n    if not is_dist_avail_and_initialized():\n        return 1\n    return dist.get_world_size()\n\n\ndef get_rank():\n    if not is_dist_avail_and_initialized():\n        return 0\n    return dist.get_rank()\n\n\ndef is_main_process():\n    return get_rank() == 0\n\n\ndef save_on_master(*args, **kwargs):\n    if is_main_process():\n        torch.save(*args, **kwargs)\n\n\ndef init_distributed_mode(args):\n    if 'RANK' in os.environ and 'WORLD_SIZE' in os.environ:\n        args.rank = int(os.environ[\"RANK\"])\n        args.world_size = int(os.environ['WORLD_SIZE'])\n        args.gpu = int(os.environ['LOCAL_RANK'])\n    elif 'SLURM_PROCID' in os.environ:\n        args.rank = int(os.environ['SLURM_PROCID'])\n        args.gpu = args.rank % torch.cuda.device_count()\n    else:\n        print('Not using distributed mode')\n        args.distributed = False\n        return\n\n    args.distributed = True\n\n    torch.cuda.set_device(args.gpu)\n    args.dist_backend = 'nccl'\n    print('| distributed init (rank {}): {}'.format(\n        args.rank, args.dist_url), flush=True)\n    torch.distributed.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n                                         world_size=args.world_size, rank=args.rank)\n    torch.distributed.barrier()\n    setup_for_distributed(args.rank == 0)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"#forrÃ¡s : https://github.com/matterport/Mask_RCNN\n\nimport math\n\ndef train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq):\n    model.train()\n    metric_logger = MetricLogger(delimiter=\"  \")\n    metric_logger.add_meter('lr', SmoothedValue(window_size=1, fmt='{value:.6f}'))\n    header = 'Epoch: [{}]'.format(epoch)\n\n    lr_scheduler = None\n    if epoch == 0:\n        warmup_factor = 1. / 1000\n        warmup_iters = min(1000, len(data_loader) - 1)\n\n        lr_scheduler = warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor)\n\n    for images, targets in metric_logger.log_every(data_loader, print_freq, header):\n        images = list(image.to(device) for image in images)\n        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n\n        loss_dict = model(images, targets)\n\n        losses = sum(loss for loss in loss_dict.values())\n\n        # reduce losses over all GPUs for logging purposes\n        loss_dict_reduced = reduce_dict(loss_dict)\n        losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n\n        loss_value = losses_reduced.item()\n\n        if not math.isfinite(loss_value):\n            print(\"Loss is {}, stopping training\".format(loss_value))\n            print(loss_dict_reduced)\n            sys.exit(1)\n\n        optimizer.zero_grad()\n        losses.backward()\n        optimizer.step()\n\n        if lr_scheduler is not None:\n            lr_scheduler.step()\n\n        metric_logger.update(loss=losses_reduced, **loss_dict_reduced)\n        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n\n    return metric_logger\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 10\nmodel.to(device)\n    \n# parameters\nparams = [p for p in model.parameters() if p.requires_grad]\noptimizer = torch.optim.SGD(params, lr=0.005,\n                                momentum=0.9, weight_decay=0.0005)\n\n\n'''\nfor epoch in range(num_epochs):\n    model.train()   \n    i = 0\n    loss_total = 0\n    for imgs, annotations in train_data_loader:\n        imgs = list(img.to(device) for img in imgs)\n        annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]\n        loss_dict = model(imgs, annotations)\n        losses = sum(loss for loss in loss_dict.values())\n        loss_value = losses.item()   \n        \n        loss_total += loss_value\n        i+=1\n        \n        if i % 50 == 0:\n            print(f\"Iteration #{i} loss: {loss_total/i}\")\n\n        optimizer.zero_grad()\n        losses.backward()\n        optimizer.step()       \n    print(f\"Epoch #{epoch} loss: {loss_total/i}\") \n'''\nfor epoch in range(num_epochs):\n    train_one_epoch(model, optimizer, train_data_loader, device, epoch, print_freq=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def apply_mask_train(image, mask, color, alpha=0.5):\n    for c in range(3):\n        for i in range(len(image[0])):\n            for j in range(len(image[0][0])):\n                if mask[j][i]==1:\n                    image[c][i][j] = image[c][i][j] * (1 - alpha) + alpha * color[c] * 255\n    return image\n\ndef apply_mask_test(image, mask, xmin, xmax, ymin, ymax, color, alpha=0.5):\n    two_third_y = (ymax-ymin)*2/3 + ymin\n    ymin = round(ymin.item())\n    ymax = round(ymax.item())\n    xmin = round(xmin.item())\n    xmax = round(xmax.item())\n    for c in range(3):\n        for i in range(ymin, ymax):\n            for j in range(xmin, xmax):\n                if mask[i][j]<1e-6:\n                    image[c][i][j] = image[c][i][j] * (1 - alpha) + alpha * color[c] * 255\n    return image\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\ndef plot_image(img_tensor, annotation, test):    \n    fig,ax = plt.subplots(1)\n    img = img_tensor.cpu().data\n\n    # Display the image\n    \n    for i in range(len(annotation[\"boxes\"])):\n        box = annotation[\"boxes\"][i]\n        xmin, ymin, xmax, ymax = box\n\n        # Create a Rectangle patch\n        rect = patches.Rectangle((xmin,ymin),(xmax-xmin),(ymax-ymin),linewidth=1,edgecolor='r',facecolor='none')\n\n        # Add the patch to the Axes\n        ax.add_patch(rect)\n        \n        label = annotation[\"labels\"][i]\n        \n        print(label)\n        toWrite = \"\"\n        if label==1:\n            toWrite += \"With Mask\"\n        elif label==2:\n            toWrite += \"Without Mask\"\n        else:\n            toWrite += \"Incorrect Mask\"\n        \n        ax.text(xmin, ymax+15, toWrite, fontsize=10, color=\"green\")\n        if(test):\n            mask = annotation[\"masks\"][i][0]\n            img = apply_mask_test(img, mask, xmin, xmax, ymin, ymax, [255, 0, 0])\n        else:\n            mask = annotation[\"masks\"][:, :, i]\n            img = apply_mask_train(img, mask, [255, 0, 0])\n        \n    ax.imshow(img.permute(1,2,0))\n    plt.show()\n  \nj = 0\nfor images, annotations in valid_data_loader:\n    imgs = list(img.to(device) for img in images)\n    targets = [{k: v.to(device) for k, v in t.items()} for t in annotations]\n    model.eval()\n    with torch.no_grad():\n        preds = model(imgs)    \n\n    for i in range(len(imgs)):\n        goodPred = { \"boxes\" : [], \"labels\" : [], \"scores\" : [], \"masks\" : []}\n        for j in range(len(preds[i][\"scores\"])):\n            if preds[i][\"scores\"][j] > 0.5:\n                goodPred[\"boxes\"].append(preds[i][\"boxes\"][j])\n                goodPred[\"labels\"].append(preds[i][\"labels\"][j])\n                goodPred[\"scores\"].append(preds[i][\"scores\"][j])\n                goodPred[\"masks\"].append(preds[i][\"masks\"][j])\n        print(\"Prediction\")\n        plot_image(imgs[i], goodPred, True)\n        \n        '''print(\"Target\")\n        plot_image(imgs[i], targets[i], False)\n        print(targets[i][\"labels\"])'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''import matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\ndef plot_image(img_tensor, annotation):    \n    fig,ax = plt.subplots(1)\n    img = img_tensor.cpu().data\n\n    # Display the image\n    ax.imshow(img.permute(1, 2, 0))\n    \n    for i in range(len(annotation[\"boxes\"])):\n        box = annotation[\"boxes\"][i]\n        xmin, ymin, xmax, ymax = box\n\n        # Create a Rectangle patch\n        rect = patches.Rectangle((xmin,ymin),(xmax-xmin),(ymax-ymin),linewidth=1,edgecolor='r',facecolor='none')\n\n        # Add the patch to the Axes\n        ax.add_patch(rect)\n        \n        label = annotation[\"labels\"][i]\n        \n        print(label)\n        toWrite = \"\"\n        if label==1:\n            toWrite += \"With Mask\"\n        elif label==2:\n            toWrite += \"Without Mask\"\n        else:\n            toWrite += \"Incorrect Mask\"\n        \n        mask = annotation[\"masks\"][i]\n        ax.text(xmin, ymax+15, toWrite, fontsize=10, color=\"green\")\n        #img = apply_mask(img, mask, [124, 135, 242])\n   \n    plt.show()\n\n\nj = 0\nfor images, annotations in valid_data_loader:\n    imgs = list(img.to(device) for img in images)\n    targets = [{k: v.to(device) for k, v in t.items()} for t in annotations]\n    model.eval()\n    with torch.no_grad():\n        preds = model(imgs)    \n\n    for i in range(len(imgs)):\n        for j in range(len(preds[i][\"scores\"])):\n            goodPred = { \"boxes\" : [], \"labels\" : [], \"scores\" : [], \"masks\": []}\n            if preds[i][\"scores\"][j] > 0.2:\n                goodPred[\"boxes\"].append(preds[i][\"boxes\"][j])\n                goodPred[\"labels\"].append(preds[i][\"labels\"][j])\n                goodPred[\"scores\"].append(preds[i][\"scores\"][j])\n                goodPred[\"masks\"].append(preds[i][\"masks\"][j])\n        print(\"Prediction\")\n        plot_image(imgs[i], goodPred)'''","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}