{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nannotations_path = []\nfor dirname, _, filenames in os.walk('/kaggle/input/face-mask-detection/annotations'):\n    for filename in filenames:\n        annotations_path.append(os.path.join(dirname, filename))\nimages_path = []\nfor dirname, _, filenames in os.walk('/kaggle/input/face-mask-detection/images'):\n    for filename in filenames:\n        images_path.append(os.path.join(dirname, filename))\n        \nannotations_path.sort()\nimages_path.sort()\n\nimport torch\nprint(torch.cuda.memory_summary(device=None, abbreviated=False))\n#torch.cuda.empty_cache()\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torchvision\nfrom torchvision import transforms, datasets, models\nimport torch\nfrom PIL import Image\nimport xml.etree.ElementTree as et\n\nclass MaskDataset(object):\n    def __init__(self, transforms):\n        self.transforms = transforms\n        self.imgs = list(sorted(os.listdir(\"/kaggle/input/face-mask-detection/images/\")))\n    def __getitem__ (self, idx):\n        img_path = os.path.join('/kaggle/input/face-mask-detection/images/maksssksksss' + str(idx) + '.png')\n        annotation_path = os.path.join(\"/kaggle/input/face-mask-detection/annotations/maksssksksss\" + str(idx) + \".xml\")\n        img = Image.open(img_path).convert(\"RGB\")\n        target = {}\n        with open(annotation_path) as annotation:\n            xml = et.parse(annotation)\n            root = xml.getroot()\n            bounding_boxes = []\n            labels = []\n            for i in range(4,len(root)):\n                #bounding_boxes.append([root[i][5][0].text,\n                #                           root[i][5][1].text, root[i][5][2].text, root[i][5][3]])\n                bounding_boxes.append([int(root[i][5][0].text),\n                                           int(root[i][5][1].text), int(root[i][5][2].text), int(root[i][5][3].text)])\n                if root[i][0].text== 'with_mask':\n                    labels.append(1)\n                elif root[i][0].text=='without_mask':\n                    labels.append(2)\n                else:\n                    labels.append(3)\n            \n            boxes = torch.as_tensor(bounding_boxes, dtype=torch.float32)\n            \n            labels = torch.as_tensor(labels, dtype=torch.int64)\n            \n            img_id = torch.tensor([idx])\n            \n            target[\"boxes\"] = boxes\n            target[\"labels\"] = labels\n            target[\"image_id\"] = img_id\n            \n        if self.transforms is not None:\n            img = self.transforms(img)\n        \n        return img, target\n    \n    def __len__(self):\n        return len(self.imgs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\n\ndef collate_fn(batch):\n    return tuple(zip(*batch))\n\ntrain_dataset = []\nvalid_dataset = []\n\ndata_transform = transforms.Compose([\n        transforms.ToTensor(), \n])\n\ndataset = MaskDataset(data_transform)\nfor i in range(len(dataset)):\n    if i % 5 == 0:\n        valid_dataset.append(dataset[i])\n    else:\n        train_dataset.append(dataset[i])\n\ntrain_data_loader = torch.utils.data.DataLoader(\n  train_dataset, batch_size=4, collate_fn=collate_fn)\n\nvalid_data_loader = torch.utils.data.DataLoader(\n  valid_dataset, batch_size=4, collate_fn=collate_fn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nfor imgs, annotations in train_data_loader:\n    imgs = list(img.to(device) for img in imgs)\n    annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]\n    print(annotations)\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n\n# load an instance segmentation model pre-trained pre-trained on COCO\nmodel = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n# get number of input features for the classifier\nin_features = model.roi_heads.box_predictor.cls_score.in_features\n# replace the pre-trained head with a new one\nmodel.roi_heads.box_predictor = FastRCNNPredictor(in_features, 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 10\nmodel.to(device)\n    \n# parameters\nparams = [p for p in model.parameters() if p.requires_grad]\noptimizer = torch.optim.SGD(params, lr=0.005,\n                                momentum=0.9, weight_decay=0.0005)\n\n\nfor epoch in range(num_epochs):\n    model.train()   \n    i = 0\n    loss_total = 0\n    for imgs, annotations in train_data_loader:\n        imgs = list(img.to(device) for img in imgs)\n        annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]\n        loss_dict = model(imgs, annotations)\n        losses = sum(loss for loss in loss_dict.values())\n        loss_value = losses.item()   \n        \n        loss_total += loss_value\n        i+=1\n        \n        if i % 50 == 0:\n            print(f\"Iteration #{i} loss: {loss_total/i}\")\n\n        optimizer.zero_grad()\n        losses.backward()\n        optimizer.step()       \n    print(f\"Epoch #{epoch} loss: {loss_total/i}\") ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\ndef plot_image(img_tensor, annotation):    \n    fig,ax = plt.subplots(1)\n    img = img_tensor.cpu().data\n\n    # Display the image\n    ax.imshow(img.permute(1, 2, 0))\n    \n    for i in range(len(annotation[\"boxes\"])):\n        box = annotation[\"boxes\"][i]\n        xmin, ymin, xmax, ymax = box\n\n        # Create a Rectangle patch\n        rect = patches.Rectangle((xmin,ymin),(xmax-xmin),(ymax-ymin),linewidth=1,edgecolor='r',facecolor='none')\n\n        # Add the patch to the Axes\n        ax.add_patch(rect)\n        \n        label = annotation[\"labels\"][i]\n        \n        print(label)\n        toWrite = \"\"\n        if label==1:\n            toWrite += \"With Mask\"\n        elif label==2:\n            toWrite += \"Without Mask\"\n        else:\n            toWrite += \"Incorrect Mask\"\n        \n        ax.text(xmin, ymax+15, toWrite, fontsize=10, color=\"green\")\n\n    plt.show()\n  \nj = 0\nframes = []\nfor images, annotations in valid_data_loader:\n    imgs = list(img.to(device) for img in images)\n    targets = [{k: v.to(device) for k, v in t.items()} for t in annotations]\n    model.eval()\n    with torch.no_grad():\n        preds = model(imgs)    \n\n    for i in range(len(imgs)):\n        goodPred = { \"boxes\" : [], \"labels\" : [], \"scores\" : []}\n        predBoxes = []\n        predLabels = []\n        predScores = []\n        groundTruthBoxes = []\n        groundTruthLabels = []\n        for j in range(len(preds[i][\"scores\"])):\n            if preds[i][\"scores\"][j] > 0.01:\n                goodPred[\"boxes\"].append(preds[i][\"boxes\"][j])\n                goodPred[\"labels\"].append(preds[i][\"labels\"][j])\n                goodPred[\"scores\"].append(preds[i][\"scores\"][j])\n                predBoxes.append(preds[i][\"boxes\"][j].cpu().detach().numpy())\n                predLabels.append(preds[i][\"labels\"][j].cpu().detach().numpy())\n                predScores.append(preds[i][\"scores\"][j].cpu().detach().numpy())\n        for k in range(len(targets[i][\"boxes\"])):\n            groundTruthBoxes.append(targets[i][\"boxes\"][k].cpu().detach().numpy())\n            groundTruthLabels.append(targets[i][\"labels\"][k].cpu().detach().numpy())\n        #print(\"Prediction\")\n        #plot_image(imgs[i], goodPred)\n        #print(goodPred[\"boxes\"])\n        print(\"Target\")\n        plot_image(imgs[i], targets[i])\n        print(targets[i][\"boxes\"])\n        print(targets[i][\"labels\"])\n        frames.append((np.array(predBoxes), np.array(predLabels), np.array(predScores), np.array(groundTruthBoxes), \n                       np.array(groundTruthLabels)))\n             ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install --upgrade git+https://github.com/MathGaron/mean_average_precision.git","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom mean_average_precision.ap_accumulator import APAccumulator\nfrom mean_average_precision.utils.bbox import jaccard\nimport math\nimport matplotlib.pyplot as plt\n\nDEBUG = False\n\n\nclass DetectionMAP:\n    def __init__(self, n_class, pr_samples=11, overlap_threshold=0.5):\n        \"\"\"\n        Running computation of average precision of n_class in a bounding box + classification task\n        :param n_class:             quantity of class\n        :param pr_samples:          quantification of threshold for pr curve\n        :param overlap_threshold:   minimum overlap threshold\n        \"\"\"\n        self.n_class = n_class\n        self.overlap_threshold = overlap_threshold\n        self.pr_scale = np.linspace(0, 1, pr_samples)\n        self.total_accumulators = []\n        self.reset_accumulators()\n\n    def reset_accumulators(self):\n        \"\"\"\n        Reset the accumulators state\n        TODO this is hard to follow... should use a better data structure\n        total_accumulators : list of list of accumulators at each pr_scale for each class\n        :return:\n        \"\"\"\n        self.total_accumulators = []\n        for i in range(len(self.pr_scale)):\n            class_accumulators = []\n            for j in range(self.n_class):\n                class_accumulators.append(APAccumulator())\n            self.total_accumulators.append(class_accumulators)\n\n    def evaluate(self, pred_bb, pred_classes, pred_conf, gt_bb, gt_classes):\n        \"\"\"\n        Update the accumulator for the running mAP evaluation.\n        For exemple, this can be called for each images\n        :param pred_bb: (np.array)      Predicted Bounding Boxes [x1, y1, x2, y2] :     Shape [n_pred, 4]\n        :param pred_classes: (np.array) Predicted Classes :                             Shape [n_pred]\n        :param pred_conf: (np.array)    Predicted Confidences [0.-1.] :                 Shape [n_pred]\n        :param gt_bb: (np.array)        Ground Truth Bounding Boxes [x1, y1, x2, y2] :  Shape [n_gt, 4]\n        :param gt_classes: (np.array)   Ground Truth Classes :                          Shape [n_gt]\n        :return:\n        \"\"\"\n\n        if pred_bb.ndim == 1:\n            pred_bb = np.repeat(pred_bb[:, np.newaxis], 4, axis=1)\n        IoUmask = None\n        if len(pred_bb) > 0:\n            IoUmask = self.compute_IoU_mask(pred_bb, gt_bb, self.overlap_threshold)\n        for accumulators, r in zip(self.total_accumulators, self.pr_scale):\n            if DEBUG:\n                print(\"Evaluate pr_scale {}\".format(r))\n            self.evaluate_(IoUmask, accumulators, pred_classes, pred_conf, gt_classes, r)\n\n    @staticmethod\n    def evaluate_(IoUmask, accumulators, pred_classes, pred_conf, gt_classes, confidence_threshold):\n        pred_classes = pred_classes.astype(np.int)\n        gt_classes = gt_classes.astype(np.int)\n\n        for i, acc in enumerate(accumulators):\n            gt_number = np.sum(gt_classes == i)\n            pred_mask = np.logical_and(pred_classes == i, pred_conf >= confidence_threshold)\n            pred_number = np.sum(pred_mask)\n            if pred_number == 0:\n                acc.inc_not_predicted(gt_number)\n                continue\n\n            IoU1 = IoUmask[pred_mask, :]\n            mask = IoU1[:, gt_classes == i]\n\n            tp = DetectionMAP.compute_true_positive(mask)\n            fp = pred_number - tp\n            fn = gt_number - tp\n            acc.inc_good_prediction(tp)\n            acc.inc_not_predicted(fn)\n            acc.inc_bad_prediction(fp)\n\n    @staticmethod\n    def compute_IoU_mask(prediction, gt, overlap_threshold):\n        IoU = jaccard(prediction, gt)\n        # for each prediction select gt with the largest IoU and ignore the others\n        for i in range(len(prediction)):\n            maxj = IoU[i, :].argmax()\n            IoU[i, :maxj] = 0\n            IoU[i, (maxj + 1):] = 0\n        # make a mask of all \"matched\" predictions vs gt\n        return IoU >= overlap_threshold\n\n    @staticmethod\n    def compute_true_positive(mask):\n        # sum all gt with prediction of its class\n        return np.sum(mask.any(axis=0))\n\n    def compute_ap(self, precisions, recalls):\n        \"\"\"\n        Compute average precision of a particular classes (cls_idx)\n        :param cls:\n        :return:\n        \"\"\"\n        previous_recall = 0\n        average_precision = 0\n        for precision, recall in zip(precisions[::-1], recalls[::-1]):\n            average_precision += precision * (recall - previous_recall)\n            previous_recall = recall\n        return average_precision\n\n    def compute_precision_recall_(self, class_index, interpolated=True):\n        precisions = []\n        recalls = []\n        for acc in self.total_accumulators:\n            precisions.append(acc[class_index].precision)\n            recalls.append(acc[class_index].recall)\n\n        if interpolated:\n            interpolated_precision = []\n            for precision in precisions:\n                last_max = 0\n                if interpolated_precision:\n                    last_max = max(interpolated_precision)\n                interpolated_precision.append(max(precision, last_max))\n            precisions = interpolated_precision\n        return precisions, recalls\n\n    def plot_pr(self, ax, class_name, precisions, recalls, average_precision):\n        ax.step(recalls, precisions, color='b', alpha=0.2,\n                where='post')\n        ax.fill_between(recalls, precisions, step='post', alpha=0.2,\n                        color='b')\n        ax.set_ylim([0.0, 1.05])\n        ax.set_xlim([0.0, 1.0])\n        ax.set_xlabel('Recall')\n        ax.set_ylabel('Precision')\n        ax.set_title('{0:} : AUC={1:0.2f}'.format(class_name, average_precision))\n\n    def plot(self, interpolated=True, class_names=None):\n        \"\"\"\n        Plot all pr-curves for each classes\n        :param interpolated: will compute the interpolated curve\n        :return:\n        \"\"\"\n        grid = int(math.ceil(math.sqrt(self.n_class)))\n        fig, axes = plt.subplots(nrows=grid, ncols=grid)\n        mean_average_precision = []\n        # TODO: data structure not optimal for this operation...\n        for i, ax in enumerate(axes.flat):\n            if i > self.n_class - 1:\n                break\n            if i == 0:\n                continue\n            precisions, recalls = self.compute_precision_recall_(i, interpolated)\n            print(i, ' ', precisions , ' ', recalls[0])\n            average_precision = self.compute_ap(precisions, recalls)\n            class_name = class_names[i] if class_names else \"Class {}\".format(i)\n            self.plot_pr(ax, class_name, precisions, recalls, average_precision)\n            mean_average_precision.append(average_precision)\n\n        plt.suptitle(\"Mean average precision : {:0.2f}\".format(sum(mean_average_precision)/len(mean_average_precision)))\n        fig.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_class = 4\n\nmAP = DetectionMAP(n_class)\nfor frame in frames:\n    mAP.evaluate(*frame)\n    \n\nmAP.plot()\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}